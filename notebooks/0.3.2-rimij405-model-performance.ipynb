{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60462dd1-07f4-46c2-9606-f0f4b4d75dea",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Checkpoint 4 - Multi-Class Classification of Walmart Product Data\n",
    "\n",
    "## Overview\n",
    "\n",
    "Our group is exploring the feasibility to predict price ranges from written Walmart product descriptions. In this report, we discuss the performance of several classifier models and review the results of our tuning process for our core algorithim.\n",
    "\n",
    "We explore the following models:\n",
    "\n",
    "1. $k$-Nearest Neighbors\n",
    "1. Logistic Regression\n",
    "1. Random Forest Classifier (Core Algorithm)\n",
    "1. RBF (Radial Basis-Function) SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69cc37ba-b438-4939-9811-b708ac11abd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Repositories\\rit\\ISTE780\\Project\n"
     ]
    }
   ],
   "source": [
    "# Enbale loading of external modules.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Set project directory to project root.\n",
    "from pathlib import Path\n",
    "PROJECT_DIR = Path.cwd().resolve().parents[0]\n",
    "%cd {PROJECT_DIR}\n",
    "\n",
    "# Import the utilities.\n",
    "from src.data import *\n",
    "from src.features import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acb8206-051b-408d-b34d-0174ce74df15",
   "metadata": {},
   "source": [
    "## Data Review\n",
    "\n",
    "The data used to fit our classifiers has received some preprocessing. Notably, we have removed features that were specific to Walmart operations (i.e., Walmart Lot and Item Numbers) and some erroneous features that were missing all or large amounts of data (i.e., the \"Available\" feature in the original dataset). We have also filtered out rows that were inappropriately listed as `$0.00 USD`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "88f7b6ed-ce44-4cc7-9277-01d3e7252586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 29604 entries, 0 to 29999\n",
      "Data columns (total 10 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   brand         29604 non-null  object \n",
      " 1   name          29604 non-null  object \n",
      " 2   description   29604 non-null  object \n",
      " 3   category_1    29604 non-null  object \n",
      " 4   category_2    29604 non-null  object \n",
      " 5   category_3    29604 non-null  object \n",
      " 6   keywords      29604 non-null  object \n",
      " 7   price_raw     29604 non-null  float64\n",
      " 8   discount_raw  29604 non-null  float64\n",
      " 9   price_range   29604 non-null  object \n",
      "dtypes: float64(2), object(8)\n",
      "memory usage: 2.5+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>category_1</th>\n",
       "      <th>category_2</th>\n",
       "      <th>category_3</th>\n",
       "      <th>keywords</th>\n",
       "      <th>price_raw</th>\n",
       "      <th>discount_raw</th>\n",
       "      <th>price_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>la cost</td>\n",
       "      <td>la costena chipotl pepper 7 oz pack 12</td>\n",
       "      <td>we aim show accur product inform manufactur su...</td>\n",
       "      <td>food</td>\n",
       "      <td>meal solut grain pasta</td>\n",
       "      <td>can good</td>\n",
       "      <td>can veget</td>\n",
       "      <td>31.93</td>\n",
       "      <td>31.93</td>\n",
       "      <td>(25, 50]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>equat</td>\n",
       "      <td>equat triamcinolon acetonid nasal allergi spra...</td>\n",
       "      <td>we aim show accur product inform manufactur su...</td>\n",
       "      <td>health</td>\n",
       "      <td>equat</td>\n",
       "      <td>equat allergi</td>\n",
       "      <td>equat sinu congest nasal care</td>\n",
       "      <td>10.48</td>\n",
       "      <td>10.48</td>\n",
       "      <td>(0, 25]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adurosmart eria</td>\n",
       "      <td>adurosmart eria soft white smart a19 light bul...</td>\n",
       "      <td>we aim show accur product inform manufactur su...</td>\n",
       "      <td>electron</td>\n",
       "      <td>smart home</td>\n",
       "      <td>smart energi light</td>\n",
       "      <td>smart light smart light bulb</td>\n",
       "      <td>10.99</td>\n",
       "      <td>10.99</td>\n",
       "      <td>(0, 25]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lowrid</td>\n",
       "      <td>24 classic adjust balloon fender set chrome bi...</td>\n",
       "      <td>we aim show accur product inform manufactur su...</td>\n",
       "      <td>sport outdoor</td>\n",
       "      <td>bike</td>\n",
       "      <td>bike accessori</td>\n",
       "      <td>bike fender</td>\n",
       "      <td>38.59</td>\n",
       "      <td>38.59</td>\n",
       "      <td>(25, 50]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>anself</td>\n",
       "      <td>eleph shape silicon drinkwar portabl silicon c...</td>\n",
       "      <td>we aim show accur product inform manufactur su...</td>\n",
       "      <td>babi</td>\n",
       "      <td>feed</td>\n",
       "      <td>sippi cup altern plastic</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5.81</td>\n",
       "      <td>5.81</td>\n",
       "      <td>(0, 25]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             brand                                               name  \\\n",
       "0          la cost             la costena chipotl pepper 7 oz pack 12   \n",
       "1            equat  equat triamcinolon acetonid nasal allergi spra...   \n",
       "2  adurosmart eria  adurosmart eria soft white smart a19 light bul...   \n",
       "3           lowrid  24 classic adjust balloon fender set chrome bi...   \n",
       "4           anself  eleph shape silicon drinkwar portabl silicon c...   \n",
       "\n",
       "                                         description     category_1  \\\n",
       "0  we aim show accur product inform manufactur su...           food   \n",
       "1  we aim show accur product inform manufactur su...         health   \n",
       "2  we aim show accur product inform manufactur su...       electron   \n",
       "3  we aim show accur product inform manufactur su...  sport outdoor   \n",
       "4  we aim show accur product inform manufactur su...           babi   \n",
       "\n",
       "               category_2                category_3  \\\n",
       "0  meal solut grain pasta                  can good   \n",
       "1                   equat             equat allergi   \n",
       "2              smart home        smart energi light   \n",
       "3                    bike            bike accessori   \n",
       "4                    feed  sippi cup altern plastic   \n",
       "\n",
       "                        keywords  price_raw  discount_raw price_range  \n",
       "0                      can veget      31.93         31.93    (25, 50]  \n",
       "1  equat sinu congest nasal care      10.48         10.48     (0, 25]  \n",
       "2   smart light smart light bulb      10.99         10.99     (0, 25]  \n",
       "3                    bike fender      38.59         38.59    (25, 50]  \n",
       "4                        unknown       5.81          5.81     (0, 25]  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "input_filepath = get_interim_filepath(\"0.1.4\", tag=\"cleaned\")\n",
    "df_input = pd.read_csv(input_filepath, index_col = 0, keep_default_na=False)\n",
    "df_input.info()\n",
    "df_input.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5616ce-0e91-4dd4-a440-119f1c450a86",
   "metadata": {},
   "source": [
    "We would like to perform some preliminary preprocessing on the text fields, to ensure they place nicely with our classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9616954-abc2-4ade-bc5a-5559bf6f3085",
   "metadata": {},
   "source": [
    "## Pipeline Setup\n",
    "\n",
    "The following steps prepare the train test splits for the classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8f6a625-9818-4168-80c7-5586e95722ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'X train: (14802, 7)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'y train: (14802,)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'X test: (14802, 7)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'y test: (14802,)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>category_1</th>\n",
       "      <th>category_2</th>\n",
       "      <th>category_3</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>la cost</td>\n",
       "      <td>la costena chipotl pepper 7 oz pack 12</td>\n",
       "      <td>we aim show accur product inform manufactur su...</td>\n",
       "      <td>food</td>\n",
       "      <td>meal solut grain pasta</td>\n",
       "      <td>can good</td>\n",
       "      <td>can veget</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>equat</td>\n",
       "      <td>equat triamcinolon acetonid nasal allergi spra...</td>\n",
       "      <td>we aim show accur product inform manufactur su...</td>\n",
       "      <td>health</td>\n",
       "      <td>equat</td>\n",
       "      <td>equat allergi</td>\n",
       "      <td>equat sinu congest nasal care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adurosmart eria</td>\n",
       "      <td>adurosmart eria soft white smart a19 light bul...</td>\n",
       "      <td>we aim show accur product inform manufactur su...</td>\n",
       "      <td>electron</td>\n",
       "      <td>smart home</td>\n",
       "      <td>smart energi light</td>\n",
       "      <td>smart light smart light bulb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lowrid</td>\n",
       "      <td>24 classic adjust balloon fender set chrome bi...</td>\n",
       "      <td>we aim show accur product inform manufactur su...</td>\n",
       "      <td>sport outdoor</td>\n",
       "      <td>bike</td>\n",
       "      <td>bike accessori</td>\n",
       "      <td>bike fender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>anself</td>\n",
       "      <td>eleph shape silicon drinkwar portabl silicon c...</td>\n",
       "      <td>we aim show accur product inform manufactur su...</td>\n",
       "      <td>babi</td>\n",
       "      <td>feed</td>\n",
       "      <td>sippi cup altern plastic</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29994</th>\n",
       "      <td>ninechef</td>\n",
       "      <td>sheng xiang zhen shengxiangzhen snack onenin c...</td>\n",
       "      <td>we aim show accur product inform manufactur su...</td>\n",
       "      <td>food</td>\n",
       "      <td>snack cooki chip</td>\n",
       "      <td>chip crisp</td>\n",
       "      <td>chip crisp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>shock sox</td>\n",
       "      <td>shock sox fork seal guard 29 36mm fork tube 4 ...</td>\n",
       "      <td>we aim show accur product inform manufactur su...</td>\n",
       "      <td>sport outdoor</td>\n",
       "      <td>bike</td>\n",
       "      <td>bike compon</td>\n",
       "      <td>bike fork</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>princ</td>\n",
       "      <td>princ gooseberri 300g</td>\n",
       "      <td>we aim show accur product inform manufactur su...</td>\n",
       "      <td>food</td>\n",
       "      <td>meal solut grain pasta</td>\n",
       "      <td>can good</td>\n",
       "      <td>can fruit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>creat ion</td>\n",
       "      <td>creat ion grace 3 4 inch straight hair iron ci...</td>\n",
       "      <td>we aim show accur product inform manufactur su...</td>\n",
       "      <td>beauti</td>\n",
       "      <td>hair care</td>\n",
       "      <td>hair style tool</td>\n",
       "      <td>flat iron hair flat iron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>takuminowaza</td>\n",
       "      <td>green bell takuminowaza two way ear pick brass...</td>\n",
       "      <td>we aim show accur product inform manufactur su...</td>\n",
       "      <td>beauti</td>\n",
       "      <td>here everi beauti</td>\n",
       "      <td>featur shop</td>\n",
       "      <td>korean japanes beauti person care ear care</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29604 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 brand                                               name  \\\n",
       "0              la cost             la costena chipotl pepper 7 oz pack 12   \n",
       "1                equat  equat triamcinolon acetonid nasal allergi spra...   \n",
       "2      adurosmart eria  adurosmart eria soft white smart a19 light bul...   \n",
       "3               lowrid  24 classic adjust balloon fender set chrome bi...   \n",
       "4               anself  eleph shape silicon drinkwar portabl silicon c...   \n",
       "...                ...                                                ...   \n",
       "29994         ninechef  sheng xiang zhen shengxiangzhen snack onenin c...   \n",
       "29996        shock sox  shock sox fork seal guard 29 36mm fork tube 4 ...   \n",
       "29997            princ                              princ gooseberri 300g   \n",
       "29998        creat ion  creat ion grace 3 4 inch straight hair iron ci...   \n",
       "29999     takuminowaza  green bell takuminowaza two way ear pick brass...   \n",
       "\n",
       "                                             description     category_1  \\\n",
       "0      we aim show accur product inform manufactur su...           food   \n",
       "1      we aim show accur product inform manufactur su...         health   \n",
       "2      we aim show accur product inform manufactur su...       electron   \n",
       "3      we aim show accur product inform manufactur su...  sport outdoor   \n",
       "4      we aim show accur product inform manufactur su...           babi   \n",
       "...                                                  ...            ...   \n",
       "29994  we aim show accur product inform manufactur su...           food   \n",
       "29996  we aim show accur product inform manufactur su...  sport outdoor   \n",
       "29997  we aim show accur product inform manufactur su...           food   \n",
       "29998  we aim show accur product inform manufactur su...         beauti   \n",
       "29999  we aim show accur product inform manufactur su...         beauti   \n",
       "\n",
       "                   category_2                category_3  \\\n",
       "0      meal solut grain pasta                  can good   \n",
       "1                       equat             equat allergi   \n",
       "2                  smart home        smart energi light   \n",
       "3                        bike            bike accessori   \n",
       "4                        feed  sippi cup altern plastic   \n",
       "...                       ...                       ...   \n",
       "29994        snack cooki chip                chip crisp   \n",
       "29996                    bike               bike compon   \n",
       "29997  meal solut grain pasta                  can good   \n",
       "29998               hair care           hair style tool   \n",
       "29999       here everi beauti               featur shop   \n",
       "\n",
       "                                         keywords  \n",
       "0                                       can veget  \n",
       "1                   equat sinu congest nasal care  \n",
       "2                    smart light smart light bulb  \n",
       "3                                     bike fender  \n",
       "4                                         unknown  \n",
       "...                                           ...  \n",
       "29994                                  chip crisp  \n",
       "29996                                   bike fork  \n",
       "29997                                   can fruit  \n",
       "29998                    flat iron hair flat iron  \n",
       "29999  korean japanes beauti person care ear care  \n",
       "\n",
       "[29604 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([2, 0, 0, ..., 0, 2, 0])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Create a 50%/50% train-test split.\n",
    "X = df_input.drop(columns=['price_raw', 'discount_raw', 'price_range'])\n",
    "y = df_input['price_range']\n",
    "\n",
    "# Encode labels.\n",
    "le = LabelEncoder()\n",
    "le.fit(products.loc[:,'price_range'].unique())\n",
    "y = le.transform(products.loc[:,'price_range'])\n",
    "\n",
    "# Split into the train test splits.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.5, random_state=100)\n",
    "display(f\"X train: {X_train.shape}\")\n",
    "display(f\"y train: {y_train.shape}\")\n",
    "display(f\"X test: {X_test.shape}\")\n",
    "display(f\"y test: {y_test.shape}\")\n",
    "display(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "685d9de1-7f00-4f49-8292-78bdc303b32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for creating the pipeline.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "def get_feature_transformer(columns, vectorizer):\n",
    "    \"\"\"Prepare the ColumnTransformer.\"\"\"\n",
    "    return ColumnTransformer([(feature, vectorizer, feature) for feature in columns], remainder = 'drop', verbose_feature_names_out=True)\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\", sublinear_tf=True, norm=\"l2\")\n",
    "column_transformer = get_feature_transformer([\"brand\", \"name\", \"description\", \"category_1\", \"category_2\", \"category_3\", \"keywords\"], vectorizer)\n",
    "\n",
    "def get_pipeline():\n",
    "    \"\"\"Get the composed Pipeline\"\"\"\n",
    "    return Pipeline([\n",
    "        (\"vect\", column_transformer),\n",
    "        (\"dim\", SelectKBest(chi2, k = 7000)),\n",
    "        (\"clf\", RandomForestClassifier())\n",
    "    ])\n",
    "\n",
    "# GridSearchCV.\n",
    "clf_rf = get_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d41b973b-ad2c-4a23-9e61-a6071d37e8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metric calculation function:\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "def show_metrics(clf, test_X, test_y):\n",
    "    print(f'Classification score: {clf.score(test_X, test_y) * 100}%')\n",
    "    print(classification_report(np.array(test_y), clf.predict(test_X), zero_division=0))\n",
    "    print(confusion_matrix(np.array(test_y), clf.predict(test_X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8890c46a-6730-4c00-b6bf-2ac395d4bfa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification score: 66.74773679232537%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.96      0.79      8395\n",
      "           1       0.76      0.48      0.59      1651\n",
      "           2       0.53      0.21      0.30      3137\n",
      "           3       0.59      0.21      0.31      1619\n",
      "\n",
      "    accuracy                           0.67     14802\n",
      "   macro avg       0.64      0.47      0.50     14802\n",
      "weighted avg       0.65      0.67      0.61     14802\n",
      "\n",
      "[[8090   20  260   25]\n",
      " [ 659  789   98  105]\n",
      " [2302   73  657  105]\n",
      " [ 908  151  216  344]]\n"
     ]
    }
   ],
   "source": [
    "clf_rf.fit(X_train, y_train)\n",
    "show_metrics(clf_rf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7519ea2-a968-4d50-b2f0-16186e265d67",
   "metadata": {},
   "source": [
    "## Baseline Classifier\n",
    "\n",
    "In order to compare our models to a reasonable baseline, we fit the model features using a `DummyClassifier` that makes predictions using simple rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad84a9b9-6f88-43d7-aee2-e28e21096071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the DummyClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# Create the DummyClassifier pipeline.\n",
    "clf_dummy = Pipeline([('vect', column_transformer),\n",
    "                      ('chi', SelectKBest(chi2, k=7000)),\n",
    "                      ('clf', DummyClassifier(strategy='most_frequent'))])\n",
    "\n",
    "# Fit the dummy classifier.\n",
    "clf_dummy.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f31d88-b89e-4a3d-b635-77a4d50fa213",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_metrics(clf_dummy, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605239f6-2485-4e0e-83ba-6ad724872a54",
   "metadata": {},
   "source": [
    "The dummy classifier serves as a useful baseline: something to compare our models' performance against. In this instance, it selects the most frequent class in the label distribution and achieves a classification score of roughly $\\approx 26.35$%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101ee804-fbd6-4be1-bebb-8e67e970dad0",
   "metadata": {},
   "source": [
    "## $k$-Nearest Neighbor Classifier\n",
    "\n",
    "K-Nearest Neighbor (KNN) is a non-parametric classification algorithm that tries to classify a given observation to a response class with the highest estimated probability. For a given positive value of K, the classifier identifies K points from the training data set that are closest to the test observation (i.e. it’s K nearest neighbors). Then it computes the estimated conditional probability using the Bayes rule and classifies the test observation to the response class with the largest probability. In our project, KNN can be used to model the List Price of a Walmart product by finding the K-nearest neighbors and assigning the list price label that has the highest estimated probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635af976-18eb-454a-9a90-fe81d2ee52b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Create the baseline kNN pipeline\n",
    "clf_kNN = Pipeline([('vect', column_transformer),\n",
    "                      ('chi',  SelectKBest(chi2, k=7000)),\n",
    "                      ('clf', KNeighborsClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d0479a-ff0a-4745-9724-c137532cd083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the kNN classifier.\n",
    "clf_kNN.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60a127f-6356-4d1c-b50e-f192faf7f06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_metrics(clf_kNN, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e4014f-2042-4b8b-a62e-12c527945e2e",
   "metadata": {},
   "source": [
    "### Tuning the $k$-Nearest Neighbor Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481f5ebe-8e8d-4900-94a1-4eabe8eda298",
   "metadata": {},
   "source": [
    "We attempted to use the elbow method to calculate an optimal $k$ for our $k$-Nearest Neighbor classifier. We narrowed it down to a range between $[5, 12]$ on a smaller sample of ~2000 before applying our algorithm to the entire ~20,000+ records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e4123c-5f10-4dec-a9c1-4a221033effc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Using the elbow method to find optimal K.\n",
    "error_rate = []\n",
    "\n",
    "tuple_range =range(5,12)\n",
    "# Will take some time\n",
    "for i in tuple_range:\n",
    "    elb_KNN = Pipeline([('vect', column_transformer),\n",
    "                      ('chi',  SelectKBest(chi2, k=7000)),\n",
    "                      ('clf', KNeighborsClassifier(n_neighbors=i))])\n",
    "    elb_KNN.fit(X_train, y_train)\n",
    "    y_i = elb_KNN.predict(X_test)\n",
    "    error_rate.append(np.mean(y_i != y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049affe8-421c-4b1a-9294-4ba45550d2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(tuple_range,error_rate,color='blue', linestyle='dashed', marker='o',\n",
    " markerfacecolor='red', markersize=10)\n",
    "plt.title('Error Rate vs. K Value')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Error Rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4a0aea-4a20-499c-afde-b2f450cff67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Setup GridSearchCV for our model.\n",
    "parameters = {'n_neighbors':range(5,10)}\n",
    "knn = KNeighborsClassifier()\n",
    "cv_KNN = GridSearchCV(knn, parameters)\n",
    "\n",
    "# Create the baseline kNN pipeline\n",
    "clf_kNN2 = Pipeline([('vect', column_transformer),\n",
    "                      ('chi',  SelectKBest(chi2, k=7000)),\n",
    "                      ('clf', cv_KNN)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c548dae9-9d28-4474-b791-33b833cfc174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the kNN classifier.\n",
    "clf_kNN2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f32a905-ae66-4908-a65c-d8cdc949bea8",
   "metadata": {},
   "source": [
    "Unfortunately, our grid search for hyperparameter tuning did not yield noticeable change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d5f8de-2129-47e7-9aa4-48d06cce685a",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_metrics(clf_kNN2, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3251131-84ab-4109-af44-d3eb55fb5596",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "Logistic Regression is a statistical model that can be used to model the probability that the response Y belongs to a particular category/class. This is different from other classification algorithms that model the response Y directly. In our project, Logistic Regression can be used to model the probability that the List Price of a Walmart product belongs to any of the labels. Logistic Regression uses a logistic function to model a statistically dependent variable (typically binary). In a binary logistic regression problem, the dependent variable (i.e., the response Y) can have two possible categorical values such as “0” and “1\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71af7f8-5e1b-4e15-a877-84bacc235d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create the pipeline.\n",
    "clf_logreg = Pipeline([('vect', column_transformer),\n",
    "                      ('chi', SelectKBest(chi2, k=7000)),\n",
    "                      ('clf', LogisticRegression(multi_class='multinomial', max_iter=1000))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27eb1c4-be90-42be-97c7-d8063d4b9935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the classifier.\n",
    "clf_logreg.fit(X_train, y_train)\n",
    "show_metrics(clf_logreg, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0e3a69-f455-4e91-9ec6-310cc93dd046",
   "metadata": {},
   "source": [
    "Logistic regression performs much better than the dummy classifier, with a $42.67$% classification score. We could choose this model to further tune, changing the decision boundary probability to do so."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2ef884-3b3a-4d72-80bb-1e235258e9bc",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "\n",
    "The random forest classifier is an ensemble estimator that fits a series of decision trees on various sub-samples of the dataset. `sklearn`'s implementation uses bootstrapping by default and uses the `gini` index as a measure of node purity in each of the trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a514ba-cd4c-414c-9b98-0ff531629faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create the pipeline.\n",
    "clf_RF = Pipeline([('vect', column_transformer),\n",
    "                   ('chi', SelectKBest(chi2, k=7000)),\n",
    "                   ('clf', RandomForestClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3317c076-a55e-44e0-8243-14dda032cad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the classifier.\n",
    "clf_RF.fit(X_train, y_train)\n",
    "show_metrics(clf_RF, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be71465e-38fc-4f47-a6fc-a4aaa723be7f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## RBF (Radial Basis Function) SVC\n",
    "\n",
    "SVC stands for C-Support Vector Classification. According to skcikit learn, \"The fit time scales at least quadratically with the number of samples and may be impractical beyond tens of thousands of samples.\" SVC is using a radial basis function for its kernel to build a \"one vs one\" model. \n",
    "\n",
    "Support Vector Machines (SVMs) are used for solving supervised learning classification problems, but they can also be used for clustering and regression algorithms. SVM tries to find a hyperplane that separates the response classes with highest margin possible. The points that lie on the margins are called support vectors. SVM uses a kernel called radial basis function to build a one vs one model for the prediction with approximately 43% accuracy. RBF is the default kernel used within scikit-learn’s SVM algorithm, and it helps to control individual observation’s effect on the overall algorithm. Large values of gamma parameter indicate greater effect of test observation on the overall algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed31d585-8e9f-47e3-b339-7dbcb2acb391",
   "metadata": {},
   "source": [
    "### Baseline SVC (RBF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9277dc8d-6965-4fc1-b864-cca78e11b5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Create the pipeline.\n",
    "clf_SVC = Pipeline([('vect', column_transformer),\n",
    "                   ('chi',  SelectKBest(chi2, k=7000)),\n",
    "                   ('clf', SVC(kernel='rbf', gamma=1, C=1, decision_function_shape='ovo'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6191930-8f38-42f3-aac1-f669be7005f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the classifier.\n",
    "clf_SVC.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c27ab3-95b8-42ae-9f63-1d0337b2fd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_metrics(clf_SVC, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf26be6f-5f3a-4c30-a351-78441b9e51c7",
   "metadata": {},
   "source": [
    "We performed a cross-validation measurement of SVC on a small subset of ~2000 samples but it did not improve classification performance, so we elected not to run the full dataset on the cross-validation score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae5aac4-805f-45c7-9476-74559e525865",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Fitting information from roughly 30,000 products is a computationally intensive process. One of the challenges we can address is fitting models on a smaller sub-sample of the data in such a way that our findings extrapolate well once we increase the amount of samples used. Initially, we setup our models using ~2000 samples from the larger population.\n",
    "\n",
    "Considering that the `DummyClassifier` has a classification score of ~26%, there is a clear improvement to the process that comes from using the other models. Hyperparameter tuning can be used to improve the performance of the different models.\n",
    "\n",
    "It is possible that we could redefine the classification we're trying to ask. Instead of the challenging multi-class classification, the problem domain could be reduced. Exploring a smaller number of labels or even turning the problem into a binary classification tasks may work well, especially in terms of something like the logistic regression model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
