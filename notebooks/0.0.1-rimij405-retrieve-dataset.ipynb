{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.0.1 - Retrieve & Clean Dataset\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook demonstrates how to download and extract the Kaggle dataset using the Kaggle API python package and the `doit` task automation tool.\n",
    "\n",
    "### Actions\n",
    "\n",
    "This notebook executes tasks using the `doit` task automation tool in order to:\n",
    "\n",
    "- Downloads the Kaggle dataset using your Kaggle API credentials (download_dataset.py).\n",
    "- Extracts the appropriate `.csv` file from the `.zip` source (unpack_dataset.py).\n",
    "\n",
    "### Dependencies\n",
    "\n",
    "Users should have installed the dependencies listed in `environment.yaml` or `requirements.txt` using the appropriate tool.\n",
    "\n",
    "Users should also have their Kaggle credentials appropriately set using one of two options:\n",
    "\n",
    "- A valid `kaggle.json` file in their home configuration folder (`~/.kaggle/kaggle.json`) or,\n",
    "- Appropriately set `KAGGLE_USERNAME` and `KAGGLE_KEY` environment variables in a `.env` file that is excluded from version control.\n",
    "\n",
    "### Targets\n",
    "\n",
    "**Targets**: This notebook outputs two files:\n",
    "\n",
    "- `data/raw/walmart-product-data-2019.zip`\n",
    "- `data/raw/marketing_sample_for_walmart_com-ecommerce__20191201_20191231__30k_data.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "The following cell changes into the root project directory in order to execute command line tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Repositories\\rit\\ISTE780\\Project\n"
     ]
    }
   ],
   "source": [
    "# Import libraries.\n",
    "from pathlib import Path\n",
    "\n",
    "# Get the project directory.\n",
    "PROJECT_DIR = Path.cwd().resolve().parents[0]\n",
    "\n",
    "%cd {PROJECT_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_data        Clean the raw dataset (.csv) and place in the interim folder.\n",
      "create_data_dir   Create the data directory.\n",
      "create_env        Create new conda environment using 'environment.yaml'.\n",
      "download_data     Download the dataset from Kaggle.\n",
      "unpack_data       Unpack the raw dataset (.zip) as the (.csv) file.\n",
      "update_env        Update existing conda environment using 'environment.yaml'.\n"
     ]
    }
   ],
   "source": [
    "# List the possible tasks.\n",
    "!doit list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_data - removing file 'data/interim/ecommerce_data-cleaned-0.1.csv'\n",
      "unpack_data - removing file 'data/raw/marketing_sample_for_walmart_com-ecommerce__20191201_20191231__30k_data.csv'\n",
      "download_data - removing file 'data/raw/walmart-product-data-2019.zip'\n"
     ]
    }
   ],
   "source": [
    "# Uncomment the line below if you would like fresh copies of the data.\n",
    "# !doit clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- create_data_dir\n",
      "-- create_env\n",
      "-- download_data\n",
      "-- unpack_data\n",
      "-- clean_data\n"
     ]
    }
   ],
   "source": [
    "!doit clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive D is Data\n",
      " Volume Serial Number is 6C42-7B68\n",
      "\n",
      " Directory of D:\\Repositories\\rit\\ISTE780\\Project\\data\\raw\n",
      "\n",
      "11/05/2021  04:56 PM    <DIR>          .\n",
      "11/05/2021  04:56 PM    <DIR>          ..\n",
      "11/05/2021  04:56 PM        45,653,183 marketing_sample_for_walmart_com-ecommerce__20191201_20191231__30k_data.csv\n",
      "11/05/2021  04:56 PM        14,308,028 walmart-product-data-2019.zip\n",
      "               2 File(s)     59,961,211 bytes\n",
      "               2 Dir(s)  462,156,988,416 bytes free\n"
     ]
    }
   ],
   "source": [
    "%ls \"data/raw/\"\n",
    "# Displays the files in the data/raw folder."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5b946e3ad701e39b274e0926621a4c5b53e2fa16d17112201a160d3918c4e637"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
