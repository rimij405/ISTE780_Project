{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.2.4 - EDA: Price Ranges\n",
    "\n",
    "**Overview**: This notebook is responsible for exploring the dataset. The purpose is to identify which price ranges are suitable for classification through hierarchical clustering.\n",
    "\n",
    "**Actions**: This notebook performs the following actions:\n",
    "\n",
    "- Fits an unsupervised clustering model on subset of training data for the purposes of getting price categories.\n",
    "\n",
    "**Dependencies**: This notebook depends on the following artifact(s):\n",
    "\n",
    "- `data/interim/ecommerce_data-cleaned-0.1.3.csv`\n",
    "\n",
    "**Targets**: This notebook does not output any artifacts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "The following cells import required libraries for python analysis, import the module path to access the project's `src/` module scripts, and enable autoreloading for the hot-reloading of source files outside of the notebook. These are all optional and should be included if needed for development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Repositories\\rit\\ISTE780\\Project\n"
     ]
    }
   ],
   "source": [
    "# Enable hot-reloading of external scripts.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Set project directory to project root.\n",
    "from pathlib import Path\n",
    "PROJECT_DIR = Path.cwd().resolve().parents[0]\n",
    "%cd {PROJECT_DIR}\n",
    "\n",
    "# Import utilities.\n",
    "from src.data import *\n",
    "from src.features import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('D:/Repositories/rit/ISTE780/Project/data/interim/ecommerce_data-cleaned-0.1.3.csv')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read dataset into pandas dataframe.\n",
    "input_filepath = get_interim_filepath(\"0.1.3\", tag=\"cleaned\")\n",
    "input_filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 29604 entries, 0 to 29999\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   brand         29604 non-null  object \n",
      " 1   name          29604 non-null  object \n",
      " 2   description   29604 non-null  object \n",
      " 3   category_1    29604 non-null  object \n",
      " 4   category_2    29604 non-null  object \n",
      " 5   category_3    29604 non-null  object \n",
      " 6   keywords      29604 non-null  object \n",
      " 7   price_raw     29604 non-null  float64\n",
      " 8   discount_raw  29604 non-null  float64\n",
      "dtypes: float64(2), object(7)\n",
      "memory usage: 2.3+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>category_1</th>\n",
       "      <th>category_2</th>\n",
       "      <th>category_3</th>\n",
       "      <th>keywords</th>\n",
       "      <th>price_raw</th>\n",
       "      <th>discount_raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>la cost</td>\n",
       "      <td>la costena chipotl pepper 7 oz pack 12</td>\n",
       "      <td>we aim show accur product inform manufactur su...</td>\n",
       "      <td>food</td>\n",
       "      <td>meal solut grain pasta</td>\n",
       "      <td>can good</td>\n",
       "      <td>can veget</td>\n",
       "      <td>31.93</td>\n",
       "      <td>31.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>equat</td>\n",
       "      <td>equat triamcinolon acetonid nasal allergi spra...</td>\n",
       "      <td>we aim show accur product inform manufactur su...</td>\n",
       "      <td>health</td>\n",
       "      <td>equat</td>\n",
       "      <td>equat allergi</td>\n",
       "      <td>equat sinu congest nasal care</td>\n",
       "      <td>10.48</td>\n",
       "      <td>10.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adurosmart eria</td>\n",
       "      <td>adurosmart eria soft white smart a19 light bul...</td>\n",
       "      <td>we aim show accur product inform manufactur su...</td>\n",
       "      <td>electron</td>\n",
       "      <td>smart home</td>\n",
       "      <td>smart energi light</td>\n",
       "      <td>smart light smart light bulb</td>\n",
       "      <td>10.99</td>\n",
       "      <td>10.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lowrid</td>\n",
       "      <td>24 classic adjust balloon fender set chrome bi...</td>\n",
       "      <td>we aim show accur product inform manufactur su...</td>\n",
       "      <td>sport outdoor</td>\n",
       "      <td>bike</td>\n",
       "      <td>bike accessori</td>\n",
       "      <td>bike fender</td>\n",
       "      <td>38.59</td>\n",
       "      <td>38.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>anself</td>\n",
       "      <td>eleph shape silicon drinkwar portabl silicon c...</td>\n",
       "      <td>we aim show accur product inform manufactur su...</td>\n",
       "      <td>babi</td>\n",
       "      <td>feed</td>\n",
       "      <td>sippi cup altern plastic</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5.81</td>\n",
       "      <td>5.81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             brand                                               name  \\\n",
       "0          la cost             la costena chipotl pepper 7 oz pack 12   \n",
       "1            equat  equat triamcinolon acetonid nasal allergi spra...   \n",
       "2  adurosmart eria  adurosmart eria soft white smart a19 light bul...   \n",
       "3           lowrid  24 classic adjust balloon fender set chrome bi...   \n",
       "4           anself  eleph shape silicon drinkwar portabl silicon c...   \n",
       "\n",
       "                                         description     category_1  \\\n",
       "0  we aim show accur product inform manufactur su...           food   \n",
       "1  we aim show accur product inform manufactur su...         health   \n",
       "2  we aim show accur product inform manufactur su...       electron   \n",
       "3  we aim show accur product inform manufactur su...  sport outdoor   \n",
       "4  we aim show accur product inform manufactur su...           babi   \n",
       "\n",
       "               category_2                category_3  \\\n",
       "0  meal solut grain pasta                  can good   \n",
       "1                   equat             equat allergi   \n",
       "2              smart home        smart energi light   \n",
       "3                    bike            bike accessori   \n",
       "4                    feed  sippi cup altern plastic   \n",
       "\n",
       "                        keywords  price_raw  discount_raw  \n",
       "0                      can veget      31.93         31.93  \n",
       "1  equat sinu congest nasal care      10.48         10.48  \n",
       "2   smart light smart light bulb      10.99         10.99  \n",
       "3                    bike fender      38.59         38.59  \n",
       "4                        unknown       5.81          5.81  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reference: https://stackoverflow.com/questions/10867028/get-pandas-read-csv-to-read-empty-values-as-empty-string-instead-of-nan\n",
    "# We should treat empty strings as empty instead of missing for this file.\n",
    "df_input = pd.read_csv(input_filepath, index_col = 0, keep_default_na=False)\n",
    "df_input.info()\n",
    "df_input.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Subset\n",
    "\n",
    "We split our data into appropriately sized train/test splits for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create a 50%/50% train-test split.\n",
    "X = df_input.drop(columns=['price_raw', 'discount_raw'])\n",
    "y = df_input['price_raw'].astype('int')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.5, random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Creation\n",
    "\n",
    "First we prepare our data for use within a learning model, encoding our text features appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ColumnTransformer(transformers=[('brand',\n",
       "                                 TfidfVectorizer(stop_words='english',\n",
       "                                                 sublinear_tf=True),\n",
       "                                 'brand'),\n",
       "                                ('name',\n",
       "                                 TfidfVectorizer(stop_words='english',\n",
       "                                                 sublinear_tf=True),\n",
       "                                 'name'),\n",
       "                                ('description',\n",
       "                                 TfidfVectorizer(stop_words='english',\n",
       "                                                 sublinear_tf=True),\n",
       "                                 'description'),\n",
       "                                ('category_1',\n",
       "                                 TfidfVectorizer(stop_words='english',\n",
       "                                                 sublinear_tf=True),\n",
       "                                 'category_1'),\n",
       "                                ('category_2',\n",
       "                                 TfidfVectorizer(stop_words='english',\n",
       "                                                 sublinear_tf=True),\n",
       "                                 'category_2'),\n",
       "                                ('category_3',\n",
       "                                 TfidfVectorizer(stop_words='english',\n",
       "                                                 sublinear_tf=True),\n",
       "                                 'category_3'),\n",
       "                                ('keywords',\n",
       "                                 TfidfVectorizer(stop_words='english',\n",
       "                                                 sublinear_tf=True),\n",
       "                                 'keywords')])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function for creating the pipeline.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def get_feature_transformer(columns, vectorizer):\n",
    "    \"\"\"Prepare the ColumnTransformer.\"\"\"\n",
    "    return ColumnTransformer([(feature, vectorizer, feature) for feature in columns], remainder = 'drop', verbose_feature_names_out=True)\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\", sublinear_tf=True, norm=\"l2\")\n",
    "column_transformer = get_feature_transformer([\"brand\", \"name\", \"description\", \"category_1\", \"category_2\", \"category_3\", \"keywords\"], vectorizer)\n",
    "column_transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectral Clustering\n",
    "\n",
    "Fit a cluster model to determine feature importance based on mean decrease in impurity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "# Compose pipeline for RandomForestClassifier.\n",
    "clf_cluster = Pipeline([('vect', column_transformer),\n",
    "                   ('chi2', SelectKBest(chi2, k = 10)),\n",
    "                   ('clf', SpectralClustering(n_clusters = 4, assign_labels='discretize', random_state=100))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the SpectralClustering cluster...\n",
      "Wall time: 34.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect',\n",
       "                 ColumnTransformer(transformers=[('brand',\n",
       "                                                  TfidfVectorizer(stop_words='english',\n",
       "                                                                  sublinear_tf=True),\n",
       "                                                  'brand'),\n",
       "                                                 ('name',\n",
       "                                                  TfidfVectorizer(stop_words='english',\n",
       "                                                                  sublinear_tf=True),\n",
       "                                                  'name'),\n",
       "                                                 ('description',\n",
       "                                                  TfidfVectorizer(stop_words='english',\n",
       "                                                                  sublinear_tf=True),\n",
       "                                                  'description'),\n",
       "                                                 ('category_1',\n",
       "                                                  TfidfVectorizer(stop_words='english',\n",
       "                                                                  sublinear_t...\n",
       "                                                                  sublinear_tf=True),\n",
       "                                                  'category_2'),\n",
       "                                                 ('category_3',\n",
       "                                                  TfidfVectorizer(stop_words='english',\n",
       "                                                                  sublinear_tf=True),\n",
       "                                                  'category_3'),\n",
       "                                                 ('keywords',\n",
       "                                                  TfidfVectorizer(stop_words='english',\n",
       "                                                                  sublinear_tf=True),\n",
       "                                                  'keywords')])),\n",
       "                ('chi2',\n",
       "                 SelectKBest(score_func=<function chi2 at 0x0000024E8D452B80>)),\n",
       "                ('clf',\n",
       "                 SpectralClustering(assign_labels='discretize', n_clusters=4,\n",
       "                                    random_state=100))])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Fit the model.\n",
    "print(\"Fitting the SpectralClustering cluster...\")\n",
    "clf_cluster.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(clf_cluster.named_steps['clf'].labels_)\n",
    "display(clf_cluster.named_steps['clf'].n_features_in_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "14797    0\n",
       "14798    0\n",
       "14799    0\n",
       "14800    0\n",
       "14801    0\n",
       "Length: 14802, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(clf_cluster.named_steps['clf'].labels_)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5b946e3ad701e39b274e0926621a4c5b53e2fa16d17112201a160d3918c4e637"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
