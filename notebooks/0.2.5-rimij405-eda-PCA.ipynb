{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.2.5 - EDA: PCA\n",
    "\n",
    "**Overview**: This notebook is responsible for exploring the dataset. The purpose is to identify potential for using PCA and GridSearchCV for feature selection.\n",
    "\n",
    "**Actions**: This notebook performs the following actions:\n",
    "\n",
    "- Creates a pipeline that takes advantage of the GridSearchCV parameters.\n",
    "\n",
    "**Dependencies**: This notebook depends on the following artifact(s):\n",
    "\n",
    "- `data/interim/ecommerce_data-cleaned-0.1.3.csv`\n",
    "\n",
    "**Targets**: This notebook does not output any artifacts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "The following cells import required libraries for python analysis, import the module path to access the project's `src/` module scripts, and enable autoreloading for the hot-reloading of source files outside of the notebook. These are all optional and should be included if needed for development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Repositories\\rit\\ISTE780\\Project\n"
     ]
    }
   ],
   "source": [
    "# Enable hot-reloading of external scripts.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Set project directory to project root.\n",
    "from pathlib import Path\n",
    "PROJECT_DIR = Path.cwd().resolve().parents[0]\n",
    "%cd {PROJECT_DIR}\n",
    "\n",
    "# Import utilities.\n",
    "from src.data import *\n",
    "from src.features import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('D:/Repositories/rit/ISTE780/Project/data/interim/ecommerce_data-cleaned-0.1.3.csv')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read dataset into pandas dataframe.\n",
    "input_filepath = get_interim_filepath(\"0.1.3\", tag=\"cleaned\")\n",
    "input_filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 29604 entries, 0 to 29999\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   brand         29604 non-null  object \n",
      " 1   name          29604 non-null  object \n",
      " 2   description   29604 non-null  object \n",
      " 3   category_1    29604 non-null  object \n",
      " 4   category_2    29604 non-null  object \n",
      " 5   category_3    29604 non-null  object \n",
      " 6   keywords      29604 non-null  object \n",
      " 7   price_raw     29604 non-null  float64\n",
      " 8   discount_raw  29604 non-null  float64\n",
      "dtypes: float64(2), object(7)\n",
      "memory usage: 2.3+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>category_1</th>\n",
       "      <th>category_2</th>\n",
       "      <th>category_3</th>\n",
       "      <th>keywords</th>\n",
       "      <th>price_raw</th>\n",
       "      <th>discount_raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>la cost</td>\n",
       "      <td>la costena chipotl pepper 7 oz pack 12</td>\n",
       "      <td>we aim show accur product inform manufactur su...</td>\n",
       "      <td>food</td>\n",
       "      <td>meal solut grain pasta</td>\n",
       "      <td>can good</td>\n",
       "      <td>can veget</td>\n",
       "      <td>31.93</td>\n",
       "      <td>31.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>equat</td>\n",
       "      <td>equat triamcinolon acetonid nasal allergi spra...</td>\n",
       "      <td>we aim show accur product inform manufactur su...</td>\n",
       "      <td>health</td>\n",
       "      <td>equat</td>\n",
       "      <td>equat allergi</td>\n",
       "      <td>equat sinu congest nasal care</td>\n",
       "      <td>10.48</td>\n",
       "      <td>10.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adurosmart eria</td>\n",
       "      <td>adurosmart eria soft white smart a19 light bul...</td>\n",
       "      <td>we aim show accur product inform manufactur su...</td>\n",
       "      <td>electron</td>\n",
       "      <td>smart home</td>\n",
       "      <td>smart energi light</td>\n",
       "      <td>smart light smart light bulb</td>\n",
       "      <td>10.99</td>\n",
       "      <td>10.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lowrid</td>\n",
       "      <td>24 classic adjust balloon fender set chrome bi...</td>\n",
       "      <td>we aim show accur product inform manufactur su...</td>\n",
       "      <td>sport outdoor</td>\n",
       "      <td>bike</td>\n",
       "      <td>bike accessori</td>\n",
       "      <td>bike fender</td>\n",
       "      <td>38.59</td>\n",
       "      <td>38.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>anself</td>\n",
       "      <td>eleph shape silicon drinkwar portabl silicon c...</td>\n",
       "      <td>we aim show accur product inform manufactur su...</td>\n",
       "      <td>babi</td>\n",
       "      <td>feed</td>\n",
       "      <td>sippi cup altern plastic</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5.81</td>\n",
       "      <td>5.81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             brand                                               name  \\\n",
       "0          la cost             la costena chipotl pepper 7 oz pack 12   \n",
       "1            equat  equat triamcinolon acetonid nasal allergi spra...   \n",
       "2  adurosmart eria  adurosmart eria soft white smart a19 light bul...   \n",
       "3           lowrid  24 classic adjust balloon fender set chrome bi...   \n",
       "4           anself  eleph shape silicon drinkwar portabl silicon c...   \n",
       "\n",
       "                                         description     category_1  \\\n",
       "0  we aim show accur product inform manufactur su...           food   \n",
       "1  we aim show accur product inform manufactur su...         health   \n",
       "2  we aim show accur product inform manufactur su...       electron   \n",
       "3  we aim show accur product inform manufactur su...  sport outdoor   \n",
       "4  we aim show accur product inform manufactur su...           babi   \n",
       "\n",
       "               category_2                category_3  \\\n",
       "0  meal solut grain pasta                  can good   \n",
       "1                   equat             equat allergi   \n",
       "2              smart home        smart energi light   \n",
       "3                    bike            bike accessori   \n",
       "4                    feed  sippi cup altern plastic   \n",
       "\n",
       "                        keywords  price_raw  discount_raw  \n",
       "0                      can veget      31.93         31.93  \n",
       "1  equat sinu congest nasal care      10.48         10.48  \n",
       "2   smart light smart light bulb      10.99         10.99  \n",
       "3                    bike fender      38.59         38.59  \n",
       "4                        unknown       5.81          5.81  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reference: https://stackoverflow.com/questions/10867028/get-pandas-read-csv-to-read-empty-values-as-empty-string-instead-of-nan\n",
    "# We should treat empty strings as empty instead of missing for this file.\n",
    "df_input = pd.read_csv(input_filepath, index_col = 0, keep_default_na=False)\n",
    "df_input.info()\n",
    "df_input.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Subset\n",
    "\n",
    "We split our data into appropriately sized train/test splits for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create a 50%/50% train-test split.\n",
    "X = df_input.drop(columns=['price_raw', 'discount_raw'])\n",
    "y = df_input['price_raw'].astype('int')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.5, random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Creation\n",
    "\n",
    "First we prepare our data for use within a learning model, encoding our text features appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for creating the pipeline.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def get_feature_transformer(columns, vectorizer):\n",
    "    \"\"\"Prepare the ColumnTransformer.\"\"\"\n",
    "    return ColumnTransformer([(feature, vectorizer, feature) for feature in columns], remainder = 'drop', verbose_feature_names_out=True)\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\", sublinear_tf=True, norm=\"l2\")\n",
    "column_transformer = get_feature_transformer([\"brand\", \"name\", \"description\", \"category_1\", \"category_2\", \"category_3\", \"keywords\"], vectorizer)\n",
    "\n",
    "def get_pipeline():\n",
    "    \"\"\"Get the composed Pipeline\"\"\"\n",
    "    return Pipeline([\n",
    "        (\"vect\", column_transformer),\n",
    "        (\"dim\", \"passthrough\"),\n",
    "        (\"clf\", RandomForestRegressor())\n",
    "    ])\n",
    "\n",
    "N_FEATURES = [2, 4, 10]\n",
    "\n",
    "def get_param_grid():\n",
    "    return [\n",
    "        {\n",
    "            \"dim\": [PCA(iterated_power=7), TruncatedSVD(n_iter=7)],\n",
    "            \"dim__n_components\": N_FEATURES,\n",
    "        },\n",
    "        {\n",
    "            \"dim\": [SelectKBest(chi2)],\n",
    "            \"dim__k\": N_FEATURES,\n",
    "        },\n",
    "    ]\n",
    "\n",
    "reducer_labels = [\"PCA\", \"TruncatedSVD\", \"KBest(chi2)\"]\n",
    "\n",
    "# GridSearchCV.\n",
    "grid = GridSearchCV(get_pipeline(), n_jobs=1, param_grid=get_param_grid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\effen\\.conda\\envs\\iste780\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "15 fits failed out of a total of 45.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\effen\\.conda\\envs\\iste780\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\effen\\.conda\\envs\\iste780\\lib\\site-packages\\sklearn\\pipeline.py\", line 390, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\effen\\.conda\\envs\\iste780\\lib\\site-packages\\sklearn\\pipeline.py\", line 348, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"C:\\Users\\effen\\.conda\\envs\\iste780\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\effen\\.conda\\envs\\iste780\\lib\\site-packages\\sklearn\\pipeline.py\", line 893, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"C:\\Users\\effen\\.conda\\envs\\iste780\\lib\\site-packages\\sklearn\\decomposition\\_pca.py\", line 407, in fit_transform\n",
      "    U, S, Vt = self._fit(X)\n",
      "  File \"C:\\Users\\effen\\.conda\\envs\\iste780\\lib\\site-packages\\sklearn\\decomposition\\_pca.py\", line 425, in _fit\n",
      "    raise TypeError(\n",
      "TypeError: PCA does not support sparse input. See TruncatedSVD for a possible alternative.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\effen\\.conda\\envs\\iste780\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [        nan         nan         nan -0.08668814  0.16490818  0.36916451\n",
      " -0.00050843 -0.00037828  0.00766577]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 7s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('vect',\n",
       "                                        ColumnTransformer(transformers=[('brand',\n",
       "                                                                         TfidfVectorizer(stop_words='english',\n",
       "                                                                                         sublinear_tf=True),\n",
       "                                                                         'brand'),\n",
       "                                                                        ('name',\n",
       "                                                                         TfidfVectorizer(stop_words='english',\n",
       "                                                                                         sublinear_tf=True),\n",
       "                                                                         'name'),\n",
       "                                                                        ('description',\n",
       "                                                                         TfidfVectorizer(stop_words='english',\n",
       "                                                                                         sublinear_tf=True),\n",
       "                                                                         'description'),\n",
       "                                                                        ('category_1',\n",
       "                                                                         TfidfVectorizer(stop_word...\n",
       "                                                                         'category_3'),\n",
       "                                                                        ('keywords',\n",
       "                                                                         TfidfVectorizer(stop_words='english',\n",
       "                                                                                         sublinear_tf=True),\n",
       "                                                                         'keywords')])),\n",
       "                                       ('dim', 'passthrough'),\n",
       "                                       ('clf', RandomForestRegressor())]),\n",
       "             n_jobs=1,\n",
       "             param_grid=[{'dim': [PCA(iterated_power=7),\n",
       "                                  TruncatedSVD(n_components=10, n_iter=7)],\n",
       "                          'dim__n_components': [2, 4, 10]},\n",
       "                         {'dim': [SelectKBest(score_func=<function chi2 at 0x000001D075870430>)],\n",
       "                          'dim__k': [2, 4, 10]}])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5b946e3ad701e39b274e0926621a4c5b53e2fa16d17112201a160d3918c4e637"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
